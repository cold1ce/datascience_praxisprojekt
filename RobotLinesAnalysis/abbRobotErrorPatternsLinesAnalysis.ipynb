{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hallo Herr Zimmermann,\n",
    "\n",
    " \n",
    "\n",
    "#vielen Dank für Ihre Nachricht.\n",
    "\n",
    "#Ich habe mir das Notebook angeschaut und eine Lösung vorgeschlagen. Allerdings verstehe ich das Ziel der Methode nicht ganz, von daher müssten Sie einmal prüfen, ob ich es richtig interpretiert habe.\n",
    "\n",
    "#Mein Vorschlag kann folgendes: für ein Fenster von z.B. 10 Nachrichten vorher oder nachher (Achtung: nachher ist für eine Prediction nicht verwendbar! Zukunftsinformation nennt man das) wird gezählt, wie oft die severity-Klassen 1, 2 und 3 vorkommen. Dies lege ich in drei Spalten ab: pre_no_srv_1, pre_no_srv_2, pre_no_srv_3\n",
    "\n",
    "#Die vielen Spalten, die durch das „Shiften“ zustande kommen, können Sie auch wieder löschen. Diese sind nur für den Zwischenschritt nötig.\n",
    "\n",
    "#So bewege ich mich dauerhaft in der Pandas-Welt und von der Performance (Laufzeit und Speicher) gibt es keine Problem.\n",
    "\n",
    " \n",
    "\n",
    "#Ist es das, was Sie erreichen wollten?\n",
    "\n",
    " \n",
    "\n",
    "#Hinsichtlich der Mappings habe ich Ihnen auch noch einen Vorschlag gemacht.\n",
    "\n",
    " \n",
    "\n",
    "#Viele Grüße und ein schönes Wochenende\n",
    "\n",
    "#Peer Küppers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Daten einlesen\n",
    "df_orig = pd.read_parquet(\"D:/Eclipse Python/DataScience/res/event_ano.parquet.gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_orig.set_index(\"event_timestamp\")\n",
    "del df['Unnamed: 0']\n",
    "df.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_mapping = {}\n",
    "for k, v in [(l, int(l.split(\"_\")[1])) for l in list(df.an_line.unique())]:\n",
    "    line_mapping[k] = v\n",
    "\n",
    "df[\"an_line_no\"] = df.an_line.map(line_mapping)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_mapping = {}\n",
    "for k, v in [(l, int(l.split(\"_\")[1])) for l in list(df.an_cell.unique())]:\n",
    "    cell_mapping[k] = v\n",
    "\n",
    "df[\"an_cell_no\"] = df.an_cell.map(cell_mapping)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "robot_mapping = {}\n",
    "for k, v in [(l, int(l.split(\"_\")[1])) for l in list(df.an_robot.unique())]:\n",
    "    robot_mapping[k] = v\n",
    "\n",
    "df[\"an_robot_no\"] = df.an_robot.map(robot_mapping)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "message_severity_mapping = {\"Error\":1,\"Warning\":2,\"Information\":3}\n",
    "\n",
    "df[\"message_severity\"] = df.message_severity.apply(lambda x: message_severity_mapping[x] if x in message_severity_mapping.keys() else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dfExtractMethod(df,extract_value):\n",
    "    df_extract = df.loc[df['an_line_no'] == extract_value]\n",
    "    return df_extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dfExtractErrorWarningInformationAnd10RowsUpAndDownPatternAllMethod(df,no_of_messages):\n",
    "    dataFrame = pd.DataFrame()\n",
    "    \n",
    "    for j in range(0,28):\n",
    "        df_extract = dfExtractMethod(df,j)\n",
    "        df_extract = df_extract.reset_index()\n",
    "                \n",
    "        for i in range(1,no_of_messages + 1):\n",
    "            df_extract['msg_svr_pre_{}'.format(i)] = df_extract.shift(i).message_severity\n",
    "\n",
    "        pre_column_names = ['msg_svr_pre_{}'.format(i) for i in range(1, no_of_messages + 1)]\n",
    "\n",
    "        for i in range(1, 4):\n",
    "            df_extract['pre_no_srv_{}'.format(i)] = (df_extract[pre_column_names]==i).sum(axis=1)\n",
    "        \n",
    "        dataFrame = dataFrame.append(df_extract)\n",
    "    return dataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ErrorsPerLinesPattern = dfExtractErrorWarningInformationAnd10RowsUpAndDownPatternAllMethod(df,10)\n",
    "df_ErrorsPerLinesPattern.to_parquet(\"D:/Eclipse Python/DataScience/res/event_ano_pattern_all.parquet.gzip\", compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dfExtractErrorWarningInformationAnd10RowsUpAndDownPatternSinglesMethod(df,no_of_messages):\n",
    "    for j in range(0,28):\n",
    "        df_extract = dfExtractMethod(df,j)\n",
    "        df_extract = df_extract.reset_index()\n",
    "        \n",
    "        for i in range(1,no_of_messages + 1):\n",
    "            df_extract['msg_svr_pre_{}'.format(i)] = df_extract.shift(i).message_severity\n",
    "\n",
    "        pre_column_names = ['msg_svr_pre_{}'.format(i) for i in range(1, no_of_messages + 1)]\n",
    "\n",
    "        for i in range(1, 4):\n",
    "            df_extract['pre_no_srv_{}'.format(i)] = (df_extract[pre_column_names]==i).sum(axis=1)\n",
    "    \n",
    "        df_extract.to_parquet(\"D:/Eclipse Python/DataScience/res/event_ano_pattern_single_{}.parquet.gzip\".format(j),compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfExtractErrorWarningInformationAnd10RowsUpAndDownPatternSinglesMethod(df,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dfExtractErrorWarningInformationAnd10RowsUpAndDownPatternDataSetMethod(df,no_of_messages):\n",
    "    for j in range(0,28):\n",
    "        df_extract = dfExtractMethod(df,j)\n",
    "        df_extract = df_extract.reset_index()\n",
    "        \n",
    "        for i in range(1,no_of_messages + 1):\n",
    "            if(df_extract.shift(i).message_severity == 1.0):\n",
    "                print(df_extract.shift(i))\n",
    "\n",
    "        \n",
    "        #df_extract.to_parquet(\"D:/Eclipse Python/DataScience/res/event_ano_pattern_DataSet.parquet.gzip\".format(j), compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-55-c9418bf22c41>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdfExtractErrorWarningInformationAnd10RowsUpAndDownPatternDataSetMethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-54-600230dc922b>\u001b[0m in \u001b[0;36mdfExtractErrorWarningInformationAnd10RowsUpAndDownPatternDataSetMethod\u001b[1;34m(df, no_of_messages)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mno_of_messages\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m             \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_extract\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshift\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage_severity\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_extract\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshift\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__nonzero__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1574\u001b[0m         raise ValueError(\"The truth value of a {0} is ambiguous. \"\n\u001b[0;32m   1575\u001b[0m                          \u001b[1;34m\"Use a.empty, a.bool(), a.item(), a.any() or a.all().\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1576\u001b[1;33m                          .format(self.__class__.__name__))\n\u001b[0m\u001b[0;32m   1577\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1578\u001b[0m     \u001b[0m__bool__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m__nonzero__\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all()."
     ]
    }
   ],
   "source": [
    "dfExtractErrorWarningInformationAnd10RowsUpAndDownPatternDataSetMethod(df,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
