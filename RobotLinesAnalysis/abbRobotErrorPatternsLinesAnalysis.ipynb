{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hallo Herr Zimmermann,\n",
    "\n",
    " \n",
    "\n",
    "#vielen Dank für Ihre Nachricht.\n",
    "\n",
    "#Ich habe mir das Notebook angeschaut und eine Lösung vorgeschlagen. Allerdings verstehe ich das Ziel der Methode nicht ganz, von daher müssten Sie einmal prüfen, ob ich es richtig interpretiert habe.\n",
    "\n",
    "#Mein Vorschlag kann folgendes: für ein Fenster von z.B. 10 Nachrichten vorher oder nachher (Achtung: nachher ist für eine Prediction nicht verwendbar! Zukunftsinformation nennt man das) wird gezählt, wie oft die severity-Klassen 1, 2 und 3 vorkommen. Dies lege ich in drei Spalten ab: pre_no_srv_1, pre_no_srv_2, pre_no_srv_3\n",
    "\n",
    "#Die vielen Spalten, die durch das „Shiften“ zustande kommen, können Sie auch wieder löschen. Diese sind nur für den Zwischenschritt nötig.\n",
    "\n",
    "#So bewege ich mich dauerhaft in der Pandas-Welt und von der Performance (Laufzeit und Speicher) gibt es keine Problem.\n",
    "\n",
    " \n",
    "\n",
    "#Ist es das, was Sie erreichen wollten?\n",
    "\n",
    " \n",
    "\n",
    "#Hinsichtlich der Mappings habe ich Ihnen auch noch einen Vorschlag gemacht.\n",
    "\n",
    " \n",
    "\n",
    "#Viele Grüße und ein schönes Wochenende\n",
    "\n",
    "#Peer Küppers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Daten einlesen\n",
    "df_orig = pd.read_parquet(\"D:/Eclipse Python/DataScience/res/event_ano.parquet.gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_orig.set_index(\"event_timestamp\")\n",
    "del df['Unnamed: 0']\n",
    "df.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_mapping = {}\n",
    "for k, v in [(l, int(l.split(\"_\")[1])) for l in list(df.an_line.unique())]:\n",
    "    line_mapping[k] = v\n",
    "\n",
    "df[\"an_line_no\"] = df.an_line.map(line_mapping)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_mapping = {}\n",
    "for k, v in [(l, int(l.split(\"_\")[1])) for l in list(df.an_cell.unique())]:\n",
    "    cell_mapping[k] = v\n",
    "\n",
    "df[\"an_cell_no\"] = df.an_cell.map(cell_mapping)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "robot_mapping = {}\n",
    "for k, v in [(l, int(l.split(\"_\")[1])) for l in list(df.an_robot.unique())]:\n",
    "    robot_mapping[k] = v\n",
    "\n",
    "df[\"an_robot_no\"] = df.an_robot.map(robot_mapping)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "message_severity_mapping = {\"Error\":1,\"Warning\":2,\"Information\":3}\n",
    "\n",
    "df[\"message_severity\"] = df.message_severity.apply(lambda x: message_severity_mapping[x] if x in message_severity_mapping.keys() else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dfExtractMethod(df,extract_value):\n",
    "    df_extract = df.loc[df['an_line_no'] == extract_value]\n",
    "    return df_extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dfExtractErrorWarningInformationAnd10RowsUpAndDownPatternAllMethod(df,no_of_messages):\n",
    "    dataFrame = pd.DataFrame()\n",
    "    \n",
    "    for j in range(0,28):\n",
    "        df_extract = dfExtractMethod(df,j)\n",
    "        df_extract = df_extract.reset_index()\n",
    "                \n",
    "        for i in range(1,no_of_messages + 1):\n",
    "            df_extract['msg_svr_pre_{}'.format(i)] = df_extract.shift(i).message_severity\n",
    "\n",
    "        pre_column_names = ['msg_svr_pre_{}'.format(i) for i in range(1, no_of_messages + 1)]\n",
    "\n",
    "        for i in range(1, 4):\n",
    "            df_extract['pre_no_srv_{}'.format(i)] = (df_extract[pre_column_names]==i).sum(axis=1)\n",
    "        \n",
    "        dataFrame = dataFrame.append(df_extract)\n",
    "    return dataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ErrorsPerLinesPattern = dfExtractErrorWarningInformationAnd10RowsUpAndDownPatternAllMethod(df,10)\n",
    "df_ErrorsPerLinesPattern.to_parquet(\"D:/Eclipse Python/DataScience/res/event_ano_pattern_all.parquet.gzip\", compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dfExtractErrorWarningInformationAnd10RowsUpAndDownPatternSinglesMethod(df,no_of_messages):\n",
    "    for j in range(0,28):\n",
    "        df_extract = dfExtractMethod(df,j)\n",
    "        df_extract = df_extract.reset_index()\n",
    "        \n",
    "        for i in range(1,no_of_messages + 1):\n",
    "            df_extract['msg_svr_pre_{}'.format(i)] = df_extract.shift(i).message_severity\n",
    "\n",
    "        pre_column_names = ['msg_svr_pre_{}'.format(i) for i in range(1, no_of_messages + 1)]\n",
    "\n",
    "        for i in range(1, 4):\n",
    "            df_extract['pre_no_srv_{}'.format(i)] = (df_extract[pre_column_names]==i).sum(axis=1)\n",
    "    \n",
    "        df_extract.to_parquet(\"D:/Eclipse Python/DataScience/res/event_ano_pattern_single_{}.parquet.gzip\".format(j),compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfExtractErrorWarningInformationAnd10RowsUpAndDownPatternSinglesMethod(df,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dfExtractErrorWarningInformationAnd10RowsUpAndDownPatternDataSetLinesMethod(df,no_of_messages,extract_value):\n",
    "    for i in range(0,28):\n",
    "        df_extract = dfExtractMethod(df,i)\n",
    "        df_extract = df_extract.reset_index()\n",
    "        \n",
    "        number = 0\n",
    "        size = df_extract.size\n",
    "        data1 = []\n",
    "        data2 = []\n",
    "        \n",
    "        for j in df_extract:\n",
    "            data2.append(j)\n",
    "\n",
    "        print(data2)\n",
    "        data1.append(data2)\n",
    "            \n",
    "        for k in df_extract.values:\n",
    "            if(k[3] == extract_value):\n",
    "                data3 = []\n",
    "                data4 = []\n",
    "                for l in range(1,11):\n",
    "                    if(number+l <= size and number+l >= 0):\n",
    "                        data3.append(df_extract.values[number-l])\n",
    "                        data4.append(k)\n",
    "\n",
    "                    if(l == 10):\n",
    "                        data1.append(data3)\n",
    "                        data1.append(data4[0])\n",
    "            else:\n",
    "                number = number + 1\n",
    "                continue\n",
    "        \n",
    "        print(\"Fertig{}\".format(i))\n",
    "        myErrorsPerLinesPatternArray = np.asarray(data1)\n",
    "        df_ErrorsPerLinesPattern = pd.DataFrame(myErrorsPerLinesPatternArray)\n",
    "        print(df_ErrorsPerLinesPattern)\n",
    "        df_ErrorsPerLinesPattern.to_parquet(\"D:/Eclipse Python/DataScience/res/event_ano_pattern_DataSet_per_line_line{}.parquet.gzip\".format(i), compression='gzip')\n",
    "    print(\"Fertig\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['event_timestamp', 'message_number', 'message_category', 'message_severity', 'an_title', 'an_description', 'an_line', 'an_cell', 'an_robot', 'an_line_no', 'an_cell_no', 'an_robot_no']\n",
      "Fertig0\n",
      "                                                     0\n",
      "0    [event_timestamp, message_number, message_cate...\n",
      "1    [[2016-06-30 12:37:36, 50024, Motion, 2, None,...\n",
      "2    [2016-06-30 12:40:14, 71201, IOCommunication, ...\n",
      "3    [[2016-06-30 12:40:14, 71201, IOCommunication,...\n",
      "4    [2016-06-30 12:40:14, 71201, IOCommunication, ...\n",
      "5    [[2016-06-30 12:40:15, 10150, Operational, 3, ...\n",
      "6    [2016-06-30 12:40:21, 134010, Paint, 1, None, ...\n",
      "7    [[2016-06-30 12:40:18, 10129, Operational, 3, ...\n",
      "8    [2016-06-30 12:40:22, 134010, Paint, 1, None, ...\n",
      "9    [[2016-06-30 16:38:47, 10052, Operational, 3, ...\n",
      "10   [2016-06-30 16:39:49, 71201, IOCommunication, ...\n",
      "11   [[2016-06-30 16:38:47, 10052, Operational, 3, ...\n",
      "12   [2016-06-30 16:39:49, 71201, IOCommunication, ...\n",
      "13   [[2016-06-30 16:39:50, 10010, Operational, 3, ...\n",
      "14   [2016-06-30 16:39:58, 134010, Paint, 1, None, ...\n",
      "15   [[2016-06-30 16:39:51, 10002, Operational, 3, ...\n",
      "16   [2016-06-30 16:39:58, 134010, Paint, 1, None, ...\n",
      "17   [[2016-06-30 17:09:12, 10053, Operational, 3, ...\n",
      "18   [2016-07-04 06:09:35, 71201, IOCommunication, ...\n",
      "19   [[2016-06-30 17:09:12, 10053, Operational, 3, ...\n",
      "20   [2016-07-04 06:09:35, 71201, IOCommunication, ...\n",
      "21   [[2016-07-04 06:09:36, 10015, Operational, 3, ...\n",
      "22   [2016-07-04 06:09:45, 134010, Paint, 1, None, ...\n",
      "23   [[2016-07-04 06:09:36, 10015, Operational, 3, ...\n",
      "24   [2016-07-04 06:09:45, 134010, Paint, 1, None, ...\n",
      "25   [[2016-07-04 06:09:49, 10010, Operational, 3, ...\n",
      "26   [2016-07-04 06:28:42, 50163, Motion, 1, None, ...\n",
      "27   [[2016-07-04 06:09:49, 10010, Operational, 3, ...\n",
      "28   [2016-07-04 06:28:42, 50050, Motion, 1, None, ...\n",
      "29   [[2016-07-04 06:09:49, 10010, Operational, 3, ...\n",
      "..                                                 ...\n",
      "89   [[2016-07-04 13:14:45, 50024, Motion, 2, None,...\n",
      "90   [2016-07-04 13:29:21, 134010, Paint, 1, None, ...\n",
      "91   [[2016-07-04 14:03:49, 10151, Operational, 3, ...\n",
      "92   [2016-07-04 15:26:14, 71201, IOCommunication, ...\n",
      "93   [[2016-07-04 14:03:49, 10151, Operational, 3, ...\n",
      "94   [2016-07-04 15:26:15, 100000, Internal, 1, Non...\n",
      "95   [[2016-07-04 14:04:53, 10002, Operational, 3, ...\n",
      "96   [2016-07-04 15:26:23, 134010, Paint, 1, None, ...\n",
      "97   [[2016-07-04 15:36:51, 50024, Motion, 2, None,...\n",
      "98   [2016-07-04 16:19:21, 71201, IOCommunication, ...\n",
      "99   [[2016-07-04 15:37:27, 10002, Operational, 3, ...\n",
      "100  [2016-07-04 16:19:22, 100000, Internal, 1, Non...\n",
      "101  [[2016-07-04 15:37:48, 50024, Motion, 2, None,...\n",
      "102  [2016-07-04 16:19:23, 100000, Internal, 1, Non...\n",
      "103  [[2016-07-04 15:42:32, 10002, Operational, 3, ...\n",
      "104  [2016-07-04 16:19:32, 134010, Paint, 1, None, ...\n",
      "105  [[2016-07-04 16:02:45, 10151, Operational, 3, ...\n",
      "106  [2016-07-05 15:13:21, 71201, IOCommunication, ...\n",
      "107  [[2016-07-04 16:03:03, 10125, Operational, 3, ...\n",
      "108  [2016-07-05 15:13:21, 71201, IOCommunication, ...\n",
      "109  [[2016-07-04 16:03:03, 10125, Operational, 3, ...\n",
      "110  [2016-07-05 15:13:22, 100000, Internal, 1, Non...\n",
      "111  [[2016-07-04 16:08:48, 10151, Operational, 3, ...\n",
      "112  [2016-07-05 15:13:23, 100000, Internal, 1, Non...\n",
      "113  [[2016-07-04 16:08:48, 10151, Operational, 3, ...\n",
      "114  [2016-07-05 15:13:23, 100000, Internal, 1, Non...\n",
      "115  [[2016-07-04 16:09:10, 10122, Operational, 3, ...\n",
      "116  [2016-07-05 15:13:30, 134010, Paint, 1, None, ...\n",
      "117  [[2016-07-04 16:09:27, 10002, Operational, 3, ...\n",
      "118  [2016-07-05 15:13:30, 134010, Paint, 1, None, ...\n",
      "\n",
      "[119 rows x 1 columns]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "parquet must have string column names",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-292ad1013a61>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdfExtractErrorWarningInformationAnd10RowsUpAndDownPatternDataSetLinesMethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-37-2d1ce0286753>\u001b[0m in \u001b[0;36mdfExtractErrorWarningInformationAnd10RowsUpAndDownPatternDataSetLinesMethod\u001b[1;34m(df, no_of_messages, extract_value)\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[0mdf_ErrorsPerLinesPattern\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmyErrorsPerLinesPatternArray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_ErrorsPerLinesPattern\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m         \u001b[0mdf_ErrorsPerLinesPattern\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_parquet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"D:/Eclipse Python/DataScience/res/event_ano_pattern_DataSet_per_line_line{}.parquet.gzip\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'gzip'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Fertig\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mto_parquet\u001b[1;34m(self, fname, engine, compression, **kwargs)\u001b[0m\n\u001b[0;32m   1943\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparquet\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mto_parquet\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1944\u001b[0m         to_parquet(self, fname, engine,\n\u001b[1;32m-> 1945\u001b[1;33m                    compression=compression, **kwargs)\n\u001b[0m\u001b[0;32m   1946\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1947\u001b[0m     @Substitution(header='Write out the column names. If a list of strings '\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\pandas\\io\\parquet.py\u001b[0m in \u001b[0;36mto_parquet\u001b[1;34m(df, path, engine, compression, **kwargs)\u001b[0m\n\u001b[0;32m    255\u001b[0m     \"\"\"\n\u001b[0;32m    256\u001b[0m     \u001b[0mimpl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 257\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mimpl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcompression\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\pandas\\io\\parquet.py\u001b[0m in \u001b[0;36mwrite\u001b[1;34m(self, df, path, compression, coerce_timestamps, **kwargs)\u001b[0m\n\u001b[0;32m    105\u001b[0m     def write(self, df, path, compression='snappy',\n\u001b[0;32m    106\u001b[0m               coerce_timestamps='ms', **kwargs):\n\u001b[1;32m--> 107\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalidate_dataframe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    108\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pyarrow_lt_070\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_write_lt_070\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\pandas\\io\\parquet.py\u001b[0m in \u001b[0;36mvalidate_dataframe\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m     53\u001b[0m         \u001b[1;31m# must have value column names (strings only)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minferred_type\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'string'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'unicode'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"parquet must have string column names\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m         \u001b[1;31m# index level names must be strings\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: parquet must have string column names"
     ]
    }
   ],
   "source": [
    "dfExtractErrorWarningInformationAnd10RowsUpAndDownPatternDataSetLinesMethod(df,10,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dfExtractErrorWarningInformationAnd10RowsUpAndDownPatternDataSetAllLinesMethod(df,no_of_messages):\n",
    "    for j in range(0,28):\n",
    "        df_extract = dfExtractMethod(df,j)\n",
    "        df_extract = df_extract.reset_index()\n",
    "        \n",
    "        for i in range(1,no_of_messages + 1):\n",
    "            if(df_extract.message_severity == 1):\n",
    "                \n",
    "        \n",
    "        #df_extract.to_parquet(\"D:/Eclipse Python/DataScience/res/event_ano_pattern_DataSet.parquet.gzip\".format(j), compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfExtractErrorWarningInformationAnd10RowsUpAndDownPatternDataSetAllLinesMethod(df,10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
